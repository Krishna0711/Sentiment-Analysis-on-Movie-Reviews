{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f3bbcd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/spaturi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## Import necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import nltk.data\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from collections import Counter\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,HashingVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, log_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f5e9ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abd530e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df = pd.read_csv(\"./Movie_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f3b607b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df.shape # In order to know structure of the input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fef606e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'label'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df.columns # for to column names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "093232b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df['label'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4285b228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I grew up (b. 1965) watching and loving the Th...      0\n",
       "1  When I put this movie in my DVD player, and sa...      0\n",
       "2  Why do people who do not know what a particula...      0\n",
       "3  Even though I have great interest in Biblical ...      0\n",
       "4  Im a die hard Dads Army fan and nothing will e...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df.head(5) # To get the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4386edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df.rename(columns = {'text':'movie_review','label':'opinion'}, inplace = True) # Rename the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7c3ea75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20019\n",
       "1    19981\n",
       "Name: opinion, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df.opinion.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3802036f",
   "metadata": {},
   "source": [
    "# The dataset contains balance dataset so we need not to worry "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70ef1276",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english') #Loading the english stopwords and storing in a variable\n",
    "stop_words.remove('not')\n",
    "# print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f0e3a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_mapping = {\"isn't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "\n",
    "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\", 'yticket' : 'ticket', \"yreferred\" : \"referred\", \"activestatus\" : \"actives tatus\",\n",
    "                           \n",
    "                           \"activesegment\" : \"active segment\", \"individualfinancial\" : \"individual financial\", \"ysupport\" : \"support\", \"reviewnext\" : \"review next\",\n",
    "                           \n",
    "                           \"ction\": \"action\", \"tconsultation\": \"consultation\", \"activeaccount\": \"active account\", \"nsupport\" : \"support\", \"selfservetype\" : \"self serve type\",\n",
    "                      \n",
    "                          \"individualfinancial\" : \"individual financial\", \"i'am\" : \"i am\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e6b698f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sentence):\n",
    "    sentence=str(sentence)\n",
    "    sentence = sentence.lower() # Converting the sentence into lower case\n",
    "    sentence=sentence.replace('{html}',\"\") #Removing html tags\n",
    "    cleanr = re.compile('<.*?>')        #For removing the special characters\n",
    "    cleantext = re.sub(cleanr, '', sentence)\n",
    "    rem_url=re.sub(r'http\\S+', '',cleantext) #Removing html links\n",
    "    rem_num = re.sub(r'\\b[0-9]+\\b\\s*', '', rem_url)# Removing numbers in a sentence\n",
    "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in rem_num.split(\" \")])\n",
    "    text = newString.strip(' ')  #Removing the leading spaces \n",
    "    text = re.sub(r'[^a-zA-Z]',' ', text) #Keeping only the alphabets related words\n",
    "    tokenizer = RegexpTokenizer(r'\\w+') \n",
    "    tokens = tokenizer.tokenize(text)  #tokenizing the sentence into words\n",
    "    filtered_words = [w for w in tokens if not w in stop_words] #Looping the sentces words and checking stopwords contians or not\n",
    "    #word for word in words if word not in stop\n",
    "    #stem_words=[stemmer.stem(w) for w in filtered_words]\n",
    "    lemma_words=[lemmatizer.lemmatize(w) for w in filtered_words] #lemmatizing each word\n",
    "    return \" \".join(lemma_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcf88741",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function by which we only take the important words only i.e Noun, adjective, Adverb , Verb\n",
    "def noun_words(text, verb = True, adverb = True, adjective = True):\n",
    "    sen = sp(text)\n",
    "    if verb == True:\n",
    "        verb = 'VERB'\n",
    "    else:\n",
    "        verb == False\n",
    "    if adverb == True:\n",
    "        adverb = 'ADVERB'\n",
    "    else:\n",
    "        adverb == False\n",
    "    if adjective == True:\n",
    "        adjective = 'ADJ'\n",
    "    else:\n",
    "        adjective == False\n",
    "    pun_list = []\n",
    "    for i in sen:\n",
    "        #print(i.pos_, i)\n",
    "        if i.pos_ == \"NOUN\" or i.pos_ == verb or i.pos_ == adverb or i.pos_ == adjective:\n",
    "            pun_list.append(i.text)\n",
    "    text = \" \".join(pun_list)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1acca91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df['movie_review_cleanText'] =  imdb_df['movie_review'].astype(str)\n",
    "imdb_df['movie_review_cleanText'] =  imdb_df['movie_review_cleanText'].map(preprocess)\n",
    "# imdb_df['important_words'] =  imdb_df['important_words'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd8b31bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40000 entries, 0 to 39999\n",
      "Data columns (total 3 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   movie_review            40000 non-null  object\n",
      " 1   opinion                 40000 non-null  int64 \n",
      " 2   movie_review_cleanText  40000 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 937.6+ KB\n"
     ]
    }
   ],
   "source": [
    "imdb_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddaa627c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.500475\n",
       "1    0.499525\n",
       "Name: opinion, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df.opinion.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7766e0",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffb33212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='opinion'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imdb_df.groupby(\"opinion\").size().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "546cad44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_review</th>\n",
       "      <th>opinion</th>\n",
       "      <th>movie_review_cleanText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>grew b watching loving thunderbird mate school...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "      <td>put movie dvd player sat coke chip expectation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "      <td>people not know particular time past like feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "      <td>even though great interest biblical movie bore...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "      <td>im die hard dad army fan nothing ever change g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        movie_review  opinion  \\\n",
       "0  I grew up (b. 1965) watching and loving the Th...        0   \n",
       "1  When I put this movie in my DVD player, and sa...        0   \n",
       "2  Why do people who do not know what a particula...        0   \n",
       "3  Even though I have great interest in Biblical ...        0   \n",
       "4  Im a die hard Dads Army fan and nothing will e...        1   \n",
       "\n",
       "                              movie_review_cleanText  \n",
       "0  grew b watching loving thunderbird mate school...  \n",
       "1  put movie dvd player sat coke chip expectation...  \n",
       "2  people not know particular time past like feel...  \n",
       "3  even though great interest biblical movie bore...  \n",
       "4  im die hard dad army fan nothing ever change g...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd994db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df.to_csv(\"./output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a17f4abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_review</th>\n",
       "      <th>opinion</th>\n",
       "      <th>movie_review_cleanText</th>\n",
       "      <th>word_count_before</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>grew b watching loving thunderbird mate school...</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "      <td>put movie dvd player sat coke chip expectation...</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "      <td>people not know particular time past like feel...</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "      <td>even though great interest biblical movie bore...</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "      <td>im die hard dad army fan nothing ever change g...</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A terrible movie as everyone has said. What ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>terrible movie everyone said made laugh cameo ...</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Finally watched this shocking movie last night...</td>\n",
       "      <td>1</td>\n",
       "      <td>finally watched shocking movie last night dist...</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I caught this film on AZN on cable. It sounded...</td>\n",
       "      <td>0</td>\n",
       "      <td>caught film azn cable sounded like would good ...</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>It may be the remake of 1987 Autumn's Tale aft...</td>\n",
       "      <td>1</td>\n",
       "      <td>may remake autumn tale eleven year director ma...</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>My Super Ex Girlfriend turned out to be a plea...</td>\n",
       "      <td>1</td>\n",
       "      <td>super ex girlfriend turned pleasant surprise r...</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        movie_review  opinion  \\\n",
       "0  I grew up (b. 1965) watching and loving the Th...        0   \n",
       "1  When I put this movie in my DVD player, and sa...        0   \n",
       "2  Why do people who do not know what a particula...        0   \n",
       "3  Even though I have great interest in Biblical ...        0   \n",
       "4  Im a die hard Dads Army fan and nothing will e...        1   \n",
       "5  A terrible movie as everyone has said. What ma...        0   \n",
       "6  Finally watched this shocking movie last night...        1   \n",
       "7  I caught this film on AZN on cable. It sounded...        0   \n",
       "8  It may be the remake of 1987 Autumn's Tale aft...        1   \n",
       "9  My Super Ex Girlfriend turned out to be a plea...        1   \n",
       "\n",
       "                              movie_review_cleanText  word_count_before  \n",
       "0  grew b watching loving thunderbird mate school...                151  \n",
       "1  put movie dvd player sat coke chip expectation...                326  \n",
       "2  people not know particular time past like feel...                184  \n",
       "3  even though great interest biblical movie bore...                 69  \n",
       "4  im die hard dad army fan nothing ever change g...                178  \n",
       "5  terrible movie everyone said made laugh cameo ...                102  \n",
       "6  finally watched shocking movie last night dist...                239  \n",
       "7  caught film azn cable sounded like would good ...                271  \n",
       "8  may remake autumn tale eleven year director ma...                188  \n",
       "9  super ex girlfriend turned pleasant surprise r...                282  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df['word_count_before'] = imdb_df['movie_review'].apply(lambda x: len(str(x).split(\" \")))\n",
    "imdb_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90b9b57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_review</th>\n",
       "      <th>opinion</th>\n",
       "      <th>movie_review_cleanText</th>\n",
       "      <th>word_count_before</th>\n",
       "      <th>word_count_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>grew b watching loving thunderbird mate school...</td>\n",
       "      <td>151</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "      <td>put movie dvd player sat coke chip expectation...</td>\n",
       "      <td>326</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "      <td>people not know particular time past like feel...</td>\n",
       "      <td>184</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "      <td>even though great interest biblical movie bore...</td>\n",
       "      <td>69</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "      <td>im die hard dad army fan nothing ever change g...</td>\n",
       "      <td>178</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A terrible movie as everyone has said. What ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>terrible movie everyone said made laugh cameo ...</td>\n",
       "      <td>102</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Finally watched this shocking movie last night...</td>\n",
       "      <td>1</td>\n",
       "      <td>finally watched shocking movie last night dist...</td>\n",
       "      <td>239</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I caught this film on AZN on cable. It sounded...</td>\n",
       "      <td>0</td>\n",
       "      <td>caught film azn cable sounded like would good ...</td>\n",
       "      <td>271</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>It may be the remake of 1987 Autumn's Tale aft...</td>\n",
       "      <td>1</td>\n",
       "      <td>may remake autumn tale eleven year director ma...</td>\n",
       "      <td>188</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>My Super Ex Girlfriend turned out to be a plea...</td>\n",
       "      <td>1</td>\n",
       "      <td>super ex girlfriend turned pleasant surprise r...</td>\n",
       "      <td>282</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        movie_review  opinion  \\\n",
       "0  I grew up (b. 1965) watching and loving the Th...        0   \n",
       "1  When I put this movie in my DVD player, and sa...        0   \n",
       "2  Why do people who do not know what a particula...        0   \n",
       "3  Even though I have great interest in Biblical ...        0   \n",
       "4  Im a die hard Dads Army fan and nothing will e...        1   \n",
       "5  A terrible movie as everyone has said. What ma...        0   \n",
       "6  Finally watched this shocking movie last night...        1   \n",
       "7  I caught this film on AZN on cable. It sounded...        0   \n",
       "8  It may be the remake of 1987 Autumn's Tale aft...        1   \n",
       "9  My Super Ex Girlfriend turned out to be a plea...        1   \n",
       "\n",
       "                              movie_review_cleanText  word_count_before  \\\n",
       "0  grew b watching loving thunderbird mate school...                151   \n",
       "1  put movie dvd player sat coke chip expectation...                326   \n",
       "2  people not know particular time past like feel...                184   \n",
       "3  even though great interest biblical movie bore...                 69   \n",
       "4  im die hard dad army fan nothing ever change g...                178   \n",
       "5  terrible movie everyone said made laugh cameo ...                102   \n",
       "6  finally watched shocking movie last night dist...                239   \n",
       "7  caught film azn cable sounded like would good ...                271   \n",
       "8  may remake autumn tale eleven year director ma...                188   \n",
       "9  super ex girlfriend turned pleasant surprise r...                282   \n",
       "\n",
       "   word_count_after  \n",
       "0                86  \n",
       "1               167  \n",
       "2                97  \n",
       "3                34  \n",
       "4               103  \n",
       "5                55  \n",
       "6               123  \n",
       "7               145  \n",
       "8               111  \n",
       "9               138  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df['word_count_after'] = imdb_df['movie_review_cleanText'].apply(lambda x: len(str(x).split(\" \")))\n",
    "imdb_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7f61939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['movie_review', 'opinion', 'movie_review_cleanText',\n",
       "       'word_count_before', 'word_count_after'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5c77d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    40000.000000\n",
       "mean       231.328975\n",
       "std        171.178333\n",
       "min          4.000000\n",
       "25%        126.000000\n",
       "50%        173.000000\n",
       "75%        282.000000\n",
       "max       2470.000000\n",
       "Name: word_count_before, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df.word_count_before.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0faf193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    40000.000000\n",
       "mean       120.895050\n",
       "std         90.928812\n",
       "min          3.000000\n",
       "25%         65.000000\n",
       "50%         90.000000\n",
       "75%        147.000000\n",
       "max       1428.000000\n",
       "Name: word_count_after, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df.word_count_after.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49df3af",
   "metadata": {},
   "source": [
    "# After prepocessing we can see that avg of each sentence around 120 words but before preprocessing it is around 230"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4bb8c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>opinion</th>\n",
       "      <th>word_count_before</th>\n",
       "      <th>word_count_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.499525</td>\n",
       "      <td>231.328975</td>\n",
       "      <td>120.895050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500006</td>\n",
       "      <td>171.178333</td>\n",
       "      <td>90.928812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>65.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>147.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2470.000000</td>\n",
       "      <td>1428.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            opinion  word_count_before  word_count_after\n",
       "count  40000.000000       40000.000000      40000.000000\n",
       "mean       0.499525         231.328975        120.895050\n",
       "std        0.500006         171.178333         90.928812\n",
       "min        0.000000           4.000000          3.000000\n",
       "25%        0.000000         126.000000         65.000000\n",
       "50%        0.000000         173.000000         90.000000\n",
       "75%        1.000000         282.000000        147.000000\n",
       "max        1.000000        2470.000000       1428.000000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "441fe644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_review</th>\n",
       "      <th>opinion</th>\n",
       "      <th>movie_review_cleanText</th>\n",
       "      <th>word_count_before</th>\n",
       "      <th>word_count_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36009</th>\n",
       "      <td>Primary plot!Primary direction!Poor interpreta...</td>\n",
       "      <td>0</td>\n",
       "      <td>primary plot primary direction poor interpreta...</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            movie_review  opinion  \\\n",
       "36009  Primary plot!Primary direction!Poor interpreta...        0   \n",
       "\n",
       "                                  movie_review_cleanText  word_count_before  \\\n",
       "36009  primary plot primary direction poor interpreta...                  4   \n",
       "\n",
       "       word_count_after  \n",
       "36009                 6  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df[imdb_df.word_count_before < 5] # trying to remove the sentences that contain less than 5 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba0f596",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21a35d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn import datasets, linear_model\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6150106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training, testing = train_test_split(imdb_df, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e5584ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['movie_review', 'opinion', 'movie_review_cleanText',\n",
       "       'word_count_before', 'word_count_after'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b0a779f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=training[\"movie_review_cleanText\"]\n",
    "Y_train=training[\"opinion\"]\n",
    "training_dataset_df = pd.DataFrame({'movie_review_cleanText':X_train,'opinion': Y_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4daf8f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_review_cleanText</th>\n",
       "      <th>opinion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33826</th>\n",
       "      <td>heidijean really see movie great christmas mov...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23063</th>\n",
       "      <td>plot eventy ive involves college kid play crue...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  movie_review_cleanText  opinion\n",
       "33826  heidijean really see movie great christmas mov...        0\n",
       "23063  plot eventy ive involves college kid play crue...        0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "108f75ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_case_list=[]\n",
    "for row in training_dataset_df[\"movie_review_cleanText\"]:\n",
    "    training_case_list.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "31401952",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert the text form data into vector form using bag of words and tfidf\n",
    "def vectorization_bow_tfidf(training_case_list, bow = None, tfidf = None):\n",
    "    if tfidf == True:        \n",
    "        vectorizer_i1 = TfidfVectorizer()\n",
    "        tfidf_matrix_iteartion1 = vectorizer_i1.fit_transform(training_case_list)\n",
    "    if bow == True:\n",
    "        vectorizer_i1 = CountVectorizer(analyzer='word',ngram_range=(1,3), encoding=\"ISO-8859-1\")\n",
    "        tfidf_matrix_iteartion1 = vectorizer_i1.fit_transform(training_case_list) ## Transform strings to tf-idf matrix\n",
    "\n",
    "    X_train=tfidf_matrix_iteartion1\n",
    "    y_train=training_dataset[\"opinion\"].values\n",
    "    \n",
    "    return X_train, y_train, vectorizer_i1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3387b9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the clean text got the tfidf vector form \n",
    "X_train, y_train, vectorizer_i2 = vectorization_bow_tfidf(training_dataset[\"movie_review_cleanText\"].tolist(),\\\n",
    "                                                          False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326bbc7b",
   "metadata": {},
   "source": [
    "# Training the model with the manually tagged notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e577e33a",
   "metadata": {},
   "source": [
    "# Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8189772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svc=LinearSVC()\n",
    "clf_fit_svc=clf_svc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21368c38",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "16f06619",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_nb=(MultinomialNB(fit_prior=True, class_prior=None))\n",
    "clf_fit_nb=clf_nb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310f5472",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "03b78dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr=OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=1)\n",
    "clf_fit_lr=clf_lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d197579",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f9e82853",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {'n_estimators':list(range(25,50))}\n",
    "clf_rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0f1ec216",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridcv = GridSearchCV(clf_rf, params,n_jobs=-1)\n",
    "# gridcv.fit(X_train, y_train)x\n",
    "# gridcv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cafa2484",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rf = RandomForestClassifier(n_estimators=100) \n",
    "clf_fit_rf = clf_rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fafa943",
   "metadata": {},
   "source": [
    "# Test the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0b6a5f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data_list = []\n",
    "for i in testing[\"movie_review_cleanText\"]:\n",
    "    testing_data_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bc35c93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_overall = vectorizer_i2.transform(testing_data_list)\n",
    "y_test_overall=testing['opinion'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "098500b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_cases(X_test,model_fit):\n",
    "    clf_predict=model_fit.predict(X_test)\n",
    "    return clf_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8b567d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to predict case reason for test data of SVC\n",
    "clf_predict_svc=classify_cases(X_test_overall,clf_fit_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "941872c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to predict case reason for test data of logistic regression\n",
    "clf_predict_lr=classify_cases(X_test_overall,clf_fit_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "63320413",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to predict case reason for test data of naive bayes\n",
    "clf_predict_nb=classify_cases(X_test_overall,clf_fit_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ca8e3bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to predict case reason for test data of Random Forest\n",
    "clf_predict_rf=classify_cases(X_test_overall,clf_fit_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6328db4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a432402f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_accuracy_report(y_test,clf_predict,dataset):\n",
    "    print (\"Overall Classifier's Accuracy: \", accuracy_score(y_test,clf_predict))\n",
    "    \n",
    "    print (\"############### Confusion Matrix ###############\")\n",
    "    x=confusion_matrix(y_test, clf_predict)\n",
    "    confusion_mat=pd.DataFrame(x)\n",
    "    print (confusion_mat)\n",
    "\n",
    "    print (\"############### Classification Report ###############\")\n",
    "    print(classification_report(y_test, clf_predict))\n",
    "    \n",
    "    dataset[\"actual\"]=y_test\n",
    "    dataset[\"predicted\"]=clf_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "13d1355f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Classifier's Accuracy:  0.8903787878787879\n",
      "############### Confusion Matrix ###############\n",
      "      0     1\n",
      "0  5754   787\n",
      "1   660  5999\n",
      "############### Classification Report ###############\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89      6541\n",
      "           1       0.88      0.90      0.89      6659\n",
      "\n",
      "    accuracy                           0.89     13200\n",
      "   macro avg       0.89      0.89      0.89     13200\n",
      "weighted avg       0.89      0.89      0.89     13200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate_accuracy_report(y_test_overall,clf_predict_svc,testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "56a00992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.8903787878787879\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy is {}'.format(accuracy_score(y_test_overall,clf_predict_svc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2aba47eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_review</th>\n",
       "      <th>opinion</th>\n",
       "      <th>movie_review_cleanText</th>\n",
       "      <th>word_count_before</th>\n",
       "      <th>word_count_after</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "      <th>opinion_svc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14852</th>\n",
       "      <td>What else is left to say?&lt;br /&gt;&lt;br /&gt;I've read...</td>\n",
       "      <td>0</td>\n",
       "      <td>else left say read review right however one pe...</td>\n",
       "      <td>144</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            movie_review  opinion  \\\n",
       "14852  What else is left to say?<br /><br />I've read...        0   \n",
       "\n",
       "                                  movie_review_cleanText  word_count_before  \\\n",
       "14852  else left say read review right however one pe...                144   \n",
       "\n",
       "       word_count_after  actual  predicted  opinion_svc  \n",
       "14852                69       0          0            0  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing['opinion_svc'] = clf_predict_svc\n",
    "testing.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8790bd95",
   "metadata": {},
   "source": [
    "# Test for Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e3f292c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Classifier's Accuracy:  0.8928030303030303\n",
      "############### Confusion Matrix ###############\n",
      "      0     1\n",
      "0  5741   800\n",
      "1   615  6044\n",
      "############### Classification Report ###############\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89      6541\n",
      "           1       0.88      0.91      0.90      6659\n",
      "\n",
      "    accuracy                           0.89     13200\n",
      "   macro avg       0.89      0.89      0.89     13200\n",
      "weighted avg       0.89      0.89      0.89     13200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate_accuracy_report(y_test_overall,clf_predict_lr,testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8934b3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.8928030303030303\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy is {}'.format(accuracy_score(y_test_overall,clf_predict_lr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "604aae6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_review</th>\n",
       "      <th>opinion</th>\n",
       "      <th>movie_review_cleanText</th>\n",
       "      <th>word_count_before</th>\n",
       "      <th>word_count_after</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "      <th>opinion_svc</th>\n",
       "      <th>opinion_LR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14852</th>\n",
       "      <td>What else is left to say?&lt;br /&gt;&lt;br /&gt;I've read...</td>\n",
       "      <td>0</td>\n",
       "      <td>else left say read review right however one pe...</td>\n",
       "      <td>144</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            movie_review  opinion  \\\n",
       "14852  What else is left to say?<br /><br />I've read...        0   \n",
       "\n",
       "                                  movie_review_cleanText  word_count_before  \\\n",
       "14852  else left say read review right however one pe...                144   \n",
       "\n",
       "       word_count_after  actual  predicted  opinion_svc  opinion_LR  \n",
       "14852                69       0          0            0           0  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing['opinion_LR'] = clf_predict_lr\n",
    "testing.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddaab592",
   "metadata": {},
   "source": [
    "# Test for Naive Bayes models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "09b26b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Classifier's Accuracy:  0.8600757575757576\n",
      "############### Confusion Matrix ###############\n",
      "      0     1\n",
      "0  5769   772\n",
      "1  1075  5584\n",
      "############### Classification Report ###############\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86      6541\n",
      "           1       0.88      0.84      0.86      6659\n",
      "\n",
      "    accuracy                           0.86     13200\n",
      "   macro avg       0.86      0.86      0.86     13200\n",
      "weighted avg       0.86      0.86      0.86     13200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate_accuracy_report(y_test_overall,clf_predict_nb,testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "406153f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_review</th>\n",
       "      <th>opinion</th>\n",
       "      <th>movie_review_cleanText</th>\n",
       "      <th>word_count_before</th>\n",
       "      <th>word_count_after</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "      <th>opinion_svc</th>\n",
       "      <th>opinion_LR</th>\n",
       "      <th>opinion_NB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14852</th>\n",
       "      <td>What else is left to say?&lt;br /&gt;&lt;br /&gt;I've read...</td>\n",
       "      <td>0</td>\n",
       "      <td>else left say read review right however one pe...</td>\n",
       "      <td>144</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            movie_review  opinion  \\\n",
       "14852  What else is left to say?<br /><br />I've read...        0   \n",
       "\n",
       "                                  movie_review_cleanText  word_count_before  \\\n",
       "14852  else left say read review right however one pe...                144   \n",
       "\n",
       "       word_count_after  actual  predicted  opinion_svc  opinion_LR  \\\n",
       "14852                69       0          0            0           0   \n",
       "\n",
       "       opinion_NB  \n",
       "14852           0  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing['opinion_NB'] = clf_predict_nb\n",
    "testing.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "df195dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_review</th>\n",
       "      <th>opinion</th>\n",
       "      <th>movie_review_cleanText</th>\n",
       "      <th>word_count_before</th>\n",
       "      <th>word_count_after</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "      <th>opinion_svc</th>\n",
       "      <th>opinion_LR</th>\n",
       "      <th>opinion_NB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20545</th>\n",
       "      <td>On the bright side, it ended. That's the only ...</td>\n",
       "      <td>0</td>\n",
       "      <td>bright side ended thing movie going course wor...</td>\n",
       "      <td>75</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            movie_review  opinion  \\\n",
       "20545  On the bright side, it ended. That's the only ...        0   \n",
       "\n",
       "                                  movie_review_cleanText  word_count_before  \\\n",
       "20545  bright side ended thing movie going course wor...                 75   \n",
       "\n",
       "       word_count_after  actual  predicted  opinion_svc  opinion_LR  \\\n",
       "20545                34       0          0            0           0   \n",
       "\n",
       "       opinion_NB  \n",
       "20545           0  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd50c832",
   "metadata": {},
   "source": [
    "# Test on Random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0e6cc43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing predictions on the test dataset\n",
    "clf_predict_rf = clf_rf.predict(X_test_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dea8cda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "66927651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY OF THE MODEL:  0.8384090909090909\n"
     ]
    }
   ],
   "source": [
    "# using metrics module for accuracy calculation\n",
    "print(\"ACCURACY OF THE MODEL: \", metrics.accuracy_score(y_test_overall, clf_predict_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "16620c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Classifier's Accuracy:  0.8384090909090909\n",
      "############### Confusion Matrix ###############\n",
      "      0     1\n",
      "0  5439  1102\n",
      "1  1031  5628\n",
      "############### Classification Report ###############\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.84      6541\n",
      "           1       0.84      0.85      0.84      6659\n",
      "\n",
      "    accuracy                           0.84     13200\n",
      "   macro avg       0.84      0.84      0.84     13200\n",
      "weighted avg       0.84      0.84      0.84     13200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate_accuracy_report(y_test_overall,clf_predict_rf,testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2c851deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_review</th>\n",
       "      <th>opinion</th>\n",
       "      <th>movie_review_cleanText</th>\n",
       "      <th>word_count_before</th>\n",
       "      <th>word_count_after</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "      <th>opinion_svc</th>\n",
       "      <th>opinion_LR</th>\n",
       "      <th>opinion_NB</th>\n",
       "      <th>opinion_RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14852</th>\n",
       "      <td>What else is left to say?&lt;br /&gt;&lt;br /&gt;I've read...</td>\n",
       "      <td>0</td>\n",
       "      <td>else left say read review right however one pe...</td>\n",
       "      <td>144</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            movie_review  opinion  \\\n",
       "14852  What else is left to say?<br /><br />I've read...        0   \n",
       "\n",
       "                                  movie_review_cleanText  word_count_before  \\\n",
       "14852  else left say read review right however one pe...                144   \n",
       "\n",
       "       word_count_after  actual  predicted  opinion_svc  opinion_LR  \\\n",
       "14852                69       0          0            0           0   \n",
       "\n",
       "       opinion_NB  opinion_RF  \n",
       "14852           0           0  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing['opinion_RF'] = clf_predict_rf\n",
    "testing.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "48b59bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_review</th>\n",
       "      <th>opinion</th>\n",
       "      <th>movie_review_cleanText</th>\n",
       "      <th>word_count_before</th>\n",
       "      <th>word_count_after</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "      <th>opinion_svc</th>\n",
       "      <th>opinion_LR</th>\n",
       "      <th>opinion_NB</th>\n",
       "      <th>opinion_RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21337</th>\n",
       "      <td>This is a very famous Ninja movie but it isn't...</td>\n",
       "      <td>0</td>\n",
       "      <td>famous ninja movie not nice movie want see nin...</td>\n",
       "      <td>211</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8186</th>\n",
       "      <td>Let me start by saying that if you're expectin...</td>\n",
       "      <td>1</td>\n",
       "      <td>let start saying expecting subtle humour wrong...</td>\n",
       "      <td>488</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9935</th>\n",
       "      <td>Aussie Shakespeare for 18-24 set.with blood ,b...</td>\n",
       "      <td>0</td>\n",
       "      <td>aussie shakespeare set blood blood blood good ...</td>\n",
       "      <td>150</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37375</th>\n",
       "      <td>Arthur Miller certainly knows. His stories giv...</td>\n",
       "      <td>1</td>\n",
       "      <td>arthur miller certainly know story give cleare...</td>\n",
       "      <td>63</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20716</th>\n",
       "      <td>If this movie would have been in English, all ...</td>\n",
       "      <td>0</td>\n",
       "      <td>movie would english critic would trashed langu...</td>\n",
       "      <td>331</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            movie_review  opinion  \\\n",
       "21337  This is a very famous Ninja movie but it isn't...        0   \n",
       "8186   Let me start by saying that if you're expectin...        1   \n",
       "9935   Aussie Shakespeare for 18-24 set.with blood ,b...        0   \n",
       "37375  Arthur Miller certainly knows. His stories giv...        1   \n",
       "20716  If this movie would have been in English, all ...        0   \n",
       "\n",
       "                                  movie_review_cleanText  word_count_before  \\\n",
       "21337  famous ninja movie not nice movie want see nin...                211   \n",
       "8186   let start saying expecting subtle humour wrong...                488   \n",
       "9935   aussie shakespeare set blood blood blood good ...                150   \n",
       "37375  arthur miller certainly know story give cleare...                 63   \n",
       "20716  movie would english critic would trashed langu...                331   \n",
       "\n",
       "       word_count_after  actual  predicted  opinion_svc  opinion_LR  \\\n",
       "21337               107       0          0            1           1   \n",
       "8186                233       1          0            1           1   \n",
       "9935                 70       0          1            1           1   \n",
       "37375                35       1          1            1           1   \n",
       "20716               157       0          0            0           0   \n",
       "\n",
       "       opinion_NB  opinion_RF  \n",
       "21337           0           0  \n",
       "8186            0           0  \n",
       "9935            0           1  \n",
       "37375           1           1  \n",
       "20716           0           0  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "defbaf03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 5)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf51c63",
   "metadata": {},
   "source": [
    "# Result Summary"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2890310c",
   "metadata": {},
   "source": [
    "# I had used different classification models in order to predict whether given sentence positive or negative\n",
    "# i.e Naive bayes, Random forest, Logistic Regression, SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ae5cfe",
   "metadata": {},
   "source": [
    "# Finding"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7b683bea",
   "metadata": {},
   "source": [
    "# After cleaning the reviews of movies the words contains in a sentence almost decrese by half"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd9af9c",
   "metadata": {},
   "source": [
    "# From the models logistic regression and SVC model are performed very well with a accuracy of almost 90 percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fdc2fa46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Intial expectaion I though of trying to this project using the bag of words(BOW) but after comparing the result with\\ntfidf the accurary seems to be prety good. So, I continued with tdidf'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Intial expectaion I though of trying to do this project using the bag of words(BOW) but after comparing the result with\n",
    "tfidf the accurary seems to be prety good with tfidf. So, I continued with tdidf'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23f3a1e",
   "metadata": {},
   "source": [
    "# Future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9c0ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''If there any time i thought of implementing for neural sentences also'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
